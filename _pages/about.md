---
permalink: /
title: "About Me"
excerpt: "About Me"
author_profile: true
redirect_from: 
  - /about/
  - /about.html
---

I am a research scientist in Fundamental AI Research (FAIR), [Meta AI](https://ai.meta.com/research/). My main research interest is in machine learning for speech and audio. I have worked on a few different topics, including multimodal and multilingual speech, self-supervised speech representation learning and text-to-speech synthesis. My current research is primarily focused on general audio generation.

Prior to Meta, I received my Ph.D in Computer Science from [TTI Chicago](https://www.ttic.edu/) under the advisement of [Dr. Karen Livescu](https://home.ttic.edu/~klivescu/), where I mainly worked on American sign language processing in the wild. Before that, I obtained my M.Sc from [ENSTA Paris](https://www.ensta-paris.fr/en) and [Pierre and Marie Curie University](https://sciences.sorbonne-universite.fr/en/sorbonne-universite-campus-pierre-et-marie-curie), and my B.Sc from [Shanghai Jiao Tong University](https://en.sjtu.edu.cn/).

Research Highlights
======
* [AudioBox](https://ai.meta.com/blog/audiobox-generating-audio-voice-natural-language-prompts/): A state-of-the-art unified model capable of generating various audio modalities (e.g., speech, sound effects) with description-based and example-based prompting
* [VoiceBox](https://about.fb.com/news/2023/06/introducing-voicebox-ai-for-speech-generation/): A versatile generative model that can perform a varriety of speech generation tasks (e.g., editing, sampling and styling) through in-context learning
* [CM3Leon](https://ai.meta.com/blog/generative-ai-text-images-cm3leon/): An efficient retrieval-augmented multimodal large language model that does both text-to-image and image-to-text generation
* [MMS](https://about.fb.com/news/2023/05/ai-massively-multilingual-speech-technology/): Massively Multilingual Speech models that expand text-to-speech and speech-to-text technology from around 100 languages to more than 1,100
* [Audio-Visual HuBERT](https://ai.meta.com/blog/ai-that-understands-speech-by-looking-as-well-as-hearing/): The first high-performing self-supervised model for audio-visual speech, achieving state-of-the-art performance on lip-reading and audio-visual speech recognition with much fewer labeled data
