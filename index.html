
<!DOCTYPE html>
<!-- saved from url=(0042)http://people.eecs.berkeley.edu/~avisingh/ -->
<html lang="en"><head><meta http-equiv="Content-Type" content="text/html; charset=UTF-8">

  <!-- Basic Page Needs
  –––––––––––––––––––––––––––––––––––––––––––––––––– --> 

  <title>Bowen Shi | home page</title>
  <meta name="description" content="Academic Website">
  <meta name="author" content="Bowen Shi">

  <!-- Mobile Specific Metas
  –––––––––––––––––––––––––––––––––––––––––––––––––– -->
  <meta http-equiv=”refresh” content=”0;url=http://ttic.edu/bshi/www/” />
  <meta name="viewport" content="width=device-width, initial-scale=1">

  <!-- FONT
  –––––––––––––––––––––––––––––––––––––––––––––––––– -->
  <link href="//fonts.googleapis.com/css?family=Raleway:400,300,600" rel="stylesheet" type="text/css">


  <link rel="stylesheet" href="https://bw-shi.github.io/css/normalize.css">
  <link rel="stylesheet" href="https://bw-shi.github.io/css/skeleton.css">
  <link rel="stylesheet" href="https://bw-shi.github.io/css/custom.css">
  <link rel="stylesheet" href="https://bw-shi.github.io/css/social-circles.min.css">
  <link rel="stylesheet" href="https://bw-shi.github.io/css/font-awesome.min.css"> 
  <link rel="stylesheet"
  href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.5.2/css/all.min.css">

  <style> .social{font-size:2.2rem;color:#6c6c6c;margin-inline:.05em;} </style>

  <style>
    a { text-decoration:none; }
    a { color:#7592BF; }
    a:hover {color:#7592BF;}
  </style>

  <!-- Favicon
  –––––––––––––––––––––––––––––––––––––––––––––––––– -->
  <link rel="icon" type="image/png" href="images/favicon-32x32.png">

</head>
<body>

  <div class="container">
    <div class="row">
      <div class="one-half column" style="margin-top: 9%">
        <img class="bio-image" src="https://bw-shi.github.io/images/profile.JPG">
      </div>
      <div class="one-half column" style="margin-top: 10%">
        <h3>Bowen Shi</h3>
        <p>Research Scientist<br>
        Meta<br/>
        bshi _at_ meta _dot_ com<br/></p>

        <a class="social fa-brands fa-github"     href="https://github.com/chevalierNoir"></a>
        <a class="social fa-brands fa-linkedin-in" href="https://www.linkedin.com/in/bowen-shi-6b73a290/"></a>
	<a class="social icon-scholar" href="https://scholar.google.com/citations?user=xqyoorYAAAAJ&hl=en"></a>
        <!-- <a class="social fa-brands fa-google-scholar" href="https://scholar.google.com/citations?user=xqyoorYAAAAJ&hl=en"></a> -->

        <br>

	<p>

      </div>
    </div>


    <div class="row" style="margin-top: 2%" id="about">
      <p>I am a research scientist at Meta SuperIntelligence Labs, working on speech and audio generation and understanding. I obtained my Ph.D. from <a href="https://www.ttic.edu/">TTIC</a> where I worked on sign language processing under the advisement of Prof. <a href="https://home.ttic.edu/~klivescu/">Karen Livescu</a>

    </div>
	  	  
  </div>



  <div class="container">
    <div class="row" style="margin-top: 2%" id="pubs">
      <h4>Selected Publications</h4>
    </div>
    <div class="row">
      <div class="twelve columns" style="margin-top: 0%"><p>
        <b>SAM Audio: Segment Anything in Audio</b> <br>
        <b>Bowen Shi</b>, Andros Tjandra, John Hoffman, Helin Wang, Yi-Chiao Wu, Luya Gao, Julius Richter, Matt Le, Apoorv Vyas, Sanyuan Chen, Christoph Feichtenhofer, Piotr Dollár, Wei-Ning Hsu, Ann Lee <br>
        <b>Technical Report</b> <a href="https://arxiv.org/abs/2512.18099">[paper]</a> <a href="https://ai.meta.com/samaudio/">[blog]</a> <a href="https://github.com/facebookresearch/sam-audio">[code]</a><br>
      </div>
  </div>

    <div class="row">
      <div class="twelve columns" style="margin-top: 0%"><p>
        <b>Movie Gen: A Cast of Media Foundation Models</b> <br>
        <b>Core Contributor</b>, The Movie Gen Team.<br>
        <b>Technical Report</b> <a href="https://ai.meta.com/static-resource/movie-gen-research-paper">[paper]</a> <a href="https://ai.meta.com/research/movie-gen/">[blog]</a><br>
      </div>
  </div>

    <div class="row">
      <div class="twelve columns" style="margin-top: 0%"><p>
        <b>Audiobox: Unified Audio Generation with Natural Language Prompts</b> <br>
        Apoorv Vyas<span class="symbol">&dagger;</span>, <b>Bowen Shi<span class="symbol">&dagger;</span></b>, Matthew Le<span class="symbol">&dagger;</span>, Andros Tjandra<span class="symbol">&dagger;</span>, Yi-Chiao Wu<span class="symbol">&dagger;</span>, Baishan Guo, Jiemin Zhang, Xinyue Zhang, Robert Adkins, William Ngan, Jeff Wang, Ivan Cruz, Bapi Akula, Akinniyi Akinyemi, Brian Ellis, Rashel Moritz, Yael Yungster, Alice Rakotoarison, Liang Tan, Chris Summers, Carleigh Wood, Joshua Lane, Mary Williamson, Wei-Ning Hsu <br> (&dagger;: equal contribution)
        <b>Technical Report</b> <a href="https://arxiv.org/abs/2312.15821">[paper]</a> <a href="https://ai.meta.com/blog/audiobox-generating-audio-voice-natural-language-prompts/">[blog]</a><a href="https://audiobox.metademolab.com/">[Demo]</a><br> 
      </div>
  </div>

    <div class="row">
      <div class="twelve columns" style="margin-top: 0%"><p>
          <b>Voicebox: Text-Guided Multilingual Universal Speech Generation at Scale,</b> <br>
	  Matthew Le<sup>*</sup>, Apoorv Vyas<sup>*</sup>, <b>Bowen Shi<sup>*</sup></b>, Brian Karrer<sup>*</sup>, Leda Sari, Rashel Moritz, Mary Williamson, Vimal Manohar, Yossi Adi, Jay Mahadeokar, Wei-Ning Hsu<sup>*</sup> <br>
        <b>NeurIPS 2023</b> <a href="https://arxiv.org/abs/2306.15687">[paper]</a> <a href="https://voicebox.metademolab.com/">[blog]</a><br> (*: equal contribution)
      </div>
  </div>

    <div class="row">
      <div class="twelve columns" style="margin-top: 0%"><p>
          <b>Scaling Speech Technology to 1,000+ Languages</b> <br>
	  Vineel Pratap<sup>*</sup>, Andros Tjandra<sup>*</sup>, <b>Bowen Shi<sup>*</sup></b>, Paden Tomasello, Arun Babu, Sayani Kundu, Ali Elkahky, Zhaoheng Ni, Apoorv Vyas, Maryam Fazel-Zarandi, Alexei Baevski, Yossi Adi, Xiaohui Zhang, Wei-Ning Hsu, Alexis Conneau, Michael Auli<sup>*</sup><br>
        <b>JMLR 2023</b> <a href="https://arxiv.org/abs/2305.13516">[paper]</a> <a href="https://ai.meta.com/blog/multilingual-model-speech-recognition/">[blog]</a> <a href="https://github.com/facebookresearch/fairseq/blob/main/examples/mms/README.md">[code]</a><br> (*: core contributor)
      </div>
  </div>

    <div class="row">
      <div class="twelve columns" style="margin-top: 0%"><p>
          <b>Scaling Autoregressive Multi-Modal Models: Pretraining and Instruction Tuning</b> <br>
	  Lili Yu<sup>*</sup>, Bowen Shi<sup>*</sup>, Ramakanth Pasunuru<sup>*</sup>, Benjamin Muller, Olga Golovneva, Tianlu Wang, Arun Babu, Binh Tang, Brian Karrer, Shelly Sheynin, Candace Ross, Adam Polyak, Russell Howes, Vasu Sharma, Puxin Xu, Hovhannes Tamoyan, Oron Ashual, Uriel Singer, Shang-Wen Li, Susan Zhang, Richard James, Gargi Ghosh, Yaniv Taigman, Maryam Fazel-Zarandi, Asli Celikyilmaz, Luke Zettlemoyer, Armen Aghajanyan<sup>*</sup><br>
        <b>Technical Report</b> <a href="https://arxiv.org/abs/2309.02591">[paper]</a> <a href="https://ai.meta.com/blog/generative-ai-text-images-cm3leon/">[blog]</a><br> (*: equal contribution)
      </div>
  </div>

</div>

<br>
<br>
</body>

</html>
